{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helpers\n",
    "import sys\n",
    "sys.path.insert(0,'../../')\n",
    "from utils import data_path,results_path,grid_search,estimator_result,cross_validate,evaluate_param\n",
    "from scipy.sparse import csr_matrix,save_npz,load_npz\n",
    "from sklearn.model_selection import cross_val_score,LeaveOneOut,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV,VarianceThreshold\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(data_path + 'feature_selection/' + 'per/'+'df_109_multi.pkl')\n",
    "test = pd.read_pickle(data_path + 'feature_selection/' + 'per/'+'df_test_109_multi.pkl')\n",
    "train_y = pd.read_csv(data_path + 'train_Y.csv')['CMV_status']\n",
    "test_y = pd.read_csv(data_path + 'test_Y.csv')['CMV_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train = (train - train.min()) / (train.max() - train.min())\n",
    "# # train.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))  \n",
    "# new_test = (test - test.min()) / (test.max() - test.min())\n",
    "# new_test.fillna(0,inplace=True)\n",
    "# na_TCRs = new_test.columns[new_test.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                max_depth=31, max_features='auto', max_leaf_nodes=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=1, min_samples_split=5,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=1,\n",
    "                oob_score=True, random_state=0, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_transformed = scaler.fit_transform(train)\n",
    "train_normalized = pd.DataFrame(train_transformed,columns=train.columns.values)\n",
    "\n",
    "test_transformed = scaler.fit_transform(test)\n",
    "test_normalized = pd.DataFrame(test_transformed,columns=test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=31, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "\n",
      "Cross validation:\n",
      "accuracy score 0.9079987026862029\n",
      "AUROC 0.9638969035890218\n",
      "________________________________________________________________________________\n",
      "Training set:\n",
      "accuracy score 0.9812792511700468\n",
      "AUROC 0.9967757156338471\n",
      "log-loss: 0.133048576357105\n",
      "________________________________________________________________________________\n",
      "Testing set;\n",
      "accuracy score: 0.825\n",
      "AUROC 0.92128445581131\n",
      "log-loss: 0.37701898988805144\n",
      "classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.78      0.84        69\n",
      "          1       0.75      0.88      0.81        51\n",
      "\n",
      "avg / total       0.84      0.82      0.83       120\n",
      "\n",
      "Confusion matrix:\n",
      "      CMV-  CMV+\n",
      "CMV-    54    15\n",
      "CMV+     6    45\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "estimator_result(rf,train_normalized.values,train_y,test_normalized.values,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscaler = StandardScaler()\n",
    "train_transformed2 = sscaler.fit_transform(train)\n",
    "train_normalized2 = pd.DataFrame(train_transformed2,columns=train.columns.values)\n",
    "\n",
    "test_transformed2 = sscaler.fit_transform(test)\n",
    "test_normalized2 = pd.DataFrame(test_transformed2,columns=test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=31, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "\n",
      "Cross validation:\n",
      "accuracy score 0.9079987026862029\n",
      "AUROC 0.9638969035890218\n",
      "________________________________________________________________________________\n",
      "Training set:\n",
      "accuracy score 0.9812792511700468\n",
      "AUROC 0.9967757156338471\n",
      "log-loss: 0.133056763401149\n",
      "________________________________________________________________________________\n",
      "Testing set;\n",
      "accuracy score: 0.85\n",
      "AUROC 0.9332196646774651\n",
      "log-loss: 0.355266306106166\n",
      "classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.84      0.87        69\n",
      "          1       0.80      0.86      0.83        51\n",
      "\n",
      "avg / total       0.85      0.85      0.85       120\n",
      "\n",
      "Confusion matrix:\n",
      "      CMV-  CMV+\n",
      "CMV-    58    11\n",
      "CMV+     7    44\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "estimator_result(rf,train_normalized2.values,train_y,test_normalized2.values,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicimal point movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.where((train*1e3)>1))\n",
    "print(np.where((test*1e3)>1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=31, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=180, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "\n",
      "Cross validation:\n",
      "accuracy score 0.9079987026862029\n",
      "AUROC 0.9638969035890218\n",
      "________________________________________________________________________________\n",
      "Training set:\n",
      "accuracy score 0.9812792511700468\n",
      "AUROC 0.9967855457691097\n",
      "log-loss: 0.13300830537218758\n",
      "________________________________________________________________________________\n",
      "Testing set;\n",
      "accuracy score: 0.9083333333333333\n",
      "AUROC 0.9485649332196646\n",
      "log-loss: 0.32833501100986334\n",
      "classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92        69\n",
      "          1       0.93      0.84      0.89        51\n",
      "\n",
      "avg / total       0.91      0.91      0.91       120\n",
      "\n",
      "Confusion matrix:\n",
      "      CMV-  CMV+\n",
      "CMV-    66     3\n",
      "CMV+     8    43\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "estimator_result(rf,(train*1e3).values,train_y,(test*1e3).values,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(C=0.5,intercept_scaling=1,random_state=0)\n",
    "# estimator_result(lr,new_train.values,train_y,new_test.values,test_y)\n",
    "\n",
    "# lr = LogisticRegression(random_state=0)\n",
    "# param_grid={\n",
    "#     'C':[0.001,0.01,0.1,0.5,0.8,1],\n",
    "#     'penalty':['l1','l2'],\n",
    "#     'intercept_scaling':[0.5,1,2,3,4,5,10]\n",
    "# }\n",
    "# grid_search(lr,new_train.values,train_y,new_test.values,test_y,param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3/5.1.0-gpu",
   "language": "python",
   "name": "anaconda3_5.1.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
